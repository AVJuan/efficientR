<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Efficient R programming</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="Efficient R programming">
  <meta name="generator" content="bookdown 0.0.69 and GitBook 2.6.7">

  <meta property="og:title" content="Efficient R programming" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="figures/full.png" />
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Efficient R programming" />
  
  
  <meta name="twitter:image" content="figures/full.png" />

<meta name="author" content="Colin Gillespie and Robin Lovelace">

<meta name="date" content="2016-04-29">

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="efficient-hardware.html">
<link rel="next" href="efficient-collaboration.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#package-dependencies"><i class="fa fa-check"></i><b>1.1</b> Package Dependencies</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="efficient-set-up.html"><a href="efficient-set-up.html"><i class="fa fa-check"></i><b>2</b> Efficient set-up</a><ul>
<li class="chapter" data-level="2.1" data-path="efficient-set-up.html"><a href="efficient-set-up.html#operating-system"><i class="fa fa-check"></i><b>2.1</b> Operating system</a><ul>
<li class="chapter" data-level="2.1.1" data-path="efficient-set-up.html"><a href="efficient-set-up.html#operating-system-and-resource-monitoring"><i class="fa fa-check"></i><b>2.1.1</b> Operating system and resource monitoring</a></li>
<li class="chapter" data-level="2.1.2" data-path="efficient-set-up.html"><a href="efficient-set-up.html#exercises"><i class="fa fa-check"></i><b>2.1.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="efficient-set-up.html"><a href="efficient-set-up.html#r-version"><i class="fa fa-check"></i><b>2.2</b> R version</a><ul>
<li class="chapter" data-level="2.2.1" data-path="efficient-set-up.html"><a href="efficient-set-up.html#installing-r"><i class="fa fa-check"></i><b>2.2.1</b> Installing R</a></li>
<li class="chapter" data-level="2.2.2" data-path="efficient-set-up.html"><a href="efficient-set-up.html#updating-r"><i class="fa fa-check"></i><b>2.2.2</b> Updating R</a></li>
<li class="chapter" data-level="2.2.3" data-path="efficient-set-up.html"><a href="efficient-set-up.html#installing-r-packages"><i class="fa fa-check"></i><b>2.2.3</b> Installing R packages</a></li>
<li class="chapter" data-level="2.2.4" data-path="efficient-set-up.html"><a href="efficient-set-up.html#deps"><i class="fa fa-check"></i><b>2.2.4</b> Installing R packages with dependencies</a></li>
<li class="chapter" data-level="2.2.5" data-path="efficient-set-up.html"><a href="efficient-set-up.html#updating-r-packages"><i class="fa fa-check"></i><b>2.2.5</b> Updating R packages</a></li>
<li class="chapter" data-level="2.2.6" data-path="efficient-set-up.html"><a href="efficient-set-up.html#exercises-1"><i class="fa fa-check"></i><b>2.2.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="efficient-set-up.html"><a href="efficient-set-up.html#r-startup"><i class="fa fa-check"></i><b>2.3</b> R startup</a><ul>
<li class="chapter" data-level="2.3.1" data-path="efficient-set-up.html"><a href="efficient-set-up.html#rprofile"><i class="fa fa-check"></i><b>2.3.1</b> The <code>.Rprofile</code> file</a></li>
<li class="chapter" data-level="2.3.2" data-path="efficient-set-up.html"><a href="efficient-set-up.html#example-.rprofile-settings"><i class="fa fa-check"></i><b>2.3.2</b> Example <code>.Rprofile</code> settings</a></li>
<li class="chapter" data-level="2.3.3" data-path="efficient-set-up.html"><a href="efficient-set-up.html#renviron"><i class="fa fa-check"></i><b>2.3.3</b> The <code>.Renviron</code> file</a></li>
<li class="chapter" data-level="2.3.4" data-path="efficient-set-up.html"><a href="efficient-set-up.html#exercises-2"><i class="fa fa-check"></i><b>2.3.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="efficient-set-up.html"><a href="efficient-set-up.html#rstudio"><i class="fa fa-check"></i><b>2.4</b> RStudio</a><ul>
<li class="chapter" data-level="2.4.1" data-path="efficient-set-up.html"><a href="efficient-set-up.html#install-rstudio"><i class="fa fa-check"></i><b>2.4.1</b> Installing and updating RStudio</a></li>
<li class="chapter" data-level="2.4.2" data-path="efficient-set-up.html"><a href="efficient-set-up.html#window-pane-layout"><i class="fa fa-check"></i><b>2.4.2</b> Window pane layout</a></li>
<li class="chapter" data-level="2.4.3" data-path="efficient-set-up.html"><a href="efficient-set-up.html#exercises-3"><i class="fa fa-check"></i><b>2.4.3</b> Exercises</a></li>
<li class="chapter" data-level="2.4.4" data-path="efficient-set-up.html"><a href="efficient-set-up.html#rstudio-options"><i class="fa fa-check"></i><b>2.4.4</b> RStudio options</a></li>
<li class="chapter" data-level="2.4.5" data-path="efficient-set-up.html"><a href="efficient-set-up.html#auto-completion"><i class="fa fa-check"></i><b>2.4.5</b> Auto-completion</a></li>
<li class="chapter" data-level="2.4.6" data-path="efficient-set-up.html"><a href="efficient-set-up.html#keyboard-shortcuts"><i class="fa fa-check"></i><b>2.4.6</b> Keyboard shortcuts</a></li>
<li class="chapter" data-level="2.4.7" data-path="efficient-set-up.html"><a href="efficient-set-up.html#object-display-and-output-table"><i class="fa fa-check"></i><b>2.4.7</b> Object display and output table</a></li>
<li class="chapter" data-level="2.4.8" data-path="efficient-set-up.html"><a href="efficient-set-up.html#project-management"><i class="fa fa-check"></i><b>2.4.8</b> Project management</a></li>
<li class="chapter" data-level="2.4.9" data-path="efficient-set-up.html"><a href="efficient-set-up.html#exercises-4"><i class="fa fa-check"></i><b>2.4.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="efficient-set-up.html"><a href="efficient-set-up.html#blas-and-alternative-r-interpreters"><i class="fa fa-check"></i><b>2.5</b> BLAS and alternative R interpreters</a><ul>
<li class="chapter" data-level="2.5.1" data-path="efficient-set-up.html"><a href="efficient-set-up.html#revolution-r"><i class="fa fa-check"></i><b>2.5.1</b> Revolution R</a></li>
<li class="chapter" data-level="2.5.2" data-path="efficient-set-up.html"><a href="efficient-set-up.html#other-interpreters"><i class="fa fa-check"></i><b>2.5.2</b> Other interpreters</a></li>
<li class="chapter" data-level="2.5.3" data-path="efficient-set-up.html"><a href="efficient-set-up.html#useful-blasbenchmarking-resources"><i class="fa fa-check"></i><b>2.5.3</b> Useful BLAS/benchmarking resources</a></li>
<li class="chapter" data-level="2.5.4" data-path="efficient-set-up.html"><a href="efficient-set-up.html#exercises-5"><i class="fa fa-check"></i><b>2.5.4</b> Exercises</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="efficient-hardware.html"><a href="efficient-hardware.html"><i class="fa fa-check"></i><b>3</b> Efficient hardware</a><ul>
<li class="chapter" data-level="3.1" data-path="efficient-hardware.html"><a href="efficient-hardware.html#background-what-is-a-byte"><i class="fa fa-check"></i><b>3.1</b> Background: what is a byte?</a></li>
<li class="chapter" data-level="3.2" data-path="efficient-hardware.html"><a href="efficient-hardware.html#ram"><i class="fa fa-check"></i><b>3.2</b> Random access memory: RAM</a></li>
<li class="chapter" data-level="3.3" data-path="efficient-hardware.html"><a href="efficient-hardware.html#hard-drives-hdd-vs-ssd"><i class="fa fa-check"></i><b>3.3</b> Hard drives: HDD vs SSD</a></li>
<li class="chapter" data-level="3.4" data-path="efficient-hardware.html"><a href="efficient-hardware.html#operating-systems-32-bit-or-64-bit"><i class="fa fa-check"></i><b>3.4</b> Operating systems: 32-bit or 64-bit</a></li>
<li class="chapter" data-level="3.5" data-path="efficient-hardware.html"><a href="efficient-hardware.html#central-processing-unit-cpu"><i class="fa fa-check"></i><b>3.5</b> Central processing unit (CPU)</a></li>
<li class="chapter" data-level="3.6" data-path="efficient-hardware.html"><a href="efficient-hardware.html#cloud-computing"><i class="fa fa-check"></i><b>3.6</b> Cloud computing</a><ul>
<li class="chapter" data-level="3.6.1" data-path="efficient-hardware.html"><a href="efficient-hardware.html#amazon-ec2"><i class="fa fa-check"></i><b>3.6.1</b> Amazon EC2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="efficient-workflow.html"><a href="efficient-workflow.html"><i class="fa fa-check"></i><b>4</b> Efficient workflow</a><ul>
<li class="chapter" data-level="4.1" data-path="efficient-workflow.html"><a href="efficient-workflow.html#project-planning"><i class="fa fa-check"></i><b>4.1</b> Project planning</a><ul>
<li class="chapter" data-level="4.1.1" data-path="efficient-workflow.html"><a href="efficient-workflow.html#chunking-your-work"><i class="fa fa-check"></i><b>4.1.1</b> ‘Chunking’ your work</a></li>
<li class="chapter" data-level="4.1.2" data-path="efficient-workflow.html"><a href="efficient-workflow.html#smart"><i class="fa fa-check"></i><b>4.1.2</b> Making your workflow SMART</a></li>
<li class="chapter" data-level="4.1.3" data-path="efficient-workflow.html"><a href="efficient-workflow.html#r-packages-for-planning"><i class="fa fa-check"></i><b>4.1.3</b> R packages for planning</a></li>
<li class="chapter" data-level="4.1.4" data-path="efficient-workflow.html"><a href="efficient-workflow.html#exercises-8"><i class="fa fa-check"></i><b>4.1.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="efficient-workflow.html"><a href="efficient-workflow.html#pkgs"><i class="fa fa-check"></i><b>4.2</b> Package selection</a></li>
<li class="chapter" data-level="4.3" data-path="efficient-workflow.html"><a href="efficient-workflow.html#importing-data"><i class="fa fa-check"></i><b>4.3</b> Importing data</a><ul>
<li class="chapter" data-level="4.3.1" data-path="efficient-workflow.html"><a href="efficient-workflow.html#fread"><i class="fa fa-check"></i><b>4.3.1</b> Fast data reading</a></li>
<li class="chapter" data-level="4.3.2" data-path="efficient-workflow.html"><a href="efficient-workflow.html#preprocessing-outside-r"><i class="fa fa-check"></i><b>4.3.2</b> Preprocessing outside R</a></li>
<li class="chapter" data-level="4.3.3" data-path="efficient-workflow.html"><a href="efficient-workflow.html#working-with-databases"><i class="fa fa-check"></i><b>4.3.3</b> Working with databases</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="efficient-workflow.html"><a href="efficient-workflow.html#tidying-data-with-tidyr"><i class="fa fa-check"></i><b>4.4</b> Tidying data with tidyr</a></li>
<li class="chapter" data-level="4.5" data-path="efficient-workflow.html"><a href="efficient-workflow.html#dplyr"><i class="fa fa-check"></i><b>4.5</b> Data processing with dplyr</a><ul>
<li class="chapter" data-level="4.5.1" data-path="efficient-workflow.html"><a href="efficient-workflow.html#renaming-columns"><i class="fa fa-check"></i><b>4.5.1</b> Renaming columns</a></li>
<li class="chapter" data-level="4.5.2" data-path="efficient-workflow.html"><a href="efficient-workflow.html#changing-column-classes"><i class="fa fa-check"></i><b>4.5.2</b> Changing column classes</a></li>
<li class="chapter" data-level="4.5.3" data-path="efficient-workflow.html"><a href="efficient-workflow.html#filtering-rows"><i class="fa fa-check"></i><b>4.5.3</b> Filtering rows</a></li>
<li class="chapter" data-level="4.5.4" data-path="efficient-workflow.html"><a href="efficient-workflow.html#filtering-columns"><i class="fa fa-check"></i><b>4.5.4</b> Filtering columns</a></li>
<li class="chapter" data-level="4.5.5" data-path="efficient-workflow.html"><a href="efficient-workflow.html#data-aggregation"><i class="fa fa-check"></i><b>4.5.5</b> Data aggregation</a></li>
<li class="chapter" data-level="4.5.6" data-path="efficient-workflow.html"><a href="efficient-workflow.html#chaining-operations"><i class="fa fa-check"></i><b>4.5.6</b> Chaining operations</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="efficient-workflow.html"><a href="efficient-workflow.html#data-processing-with-data.table"><i class="fa fa-check"></i><b>4.6</b> Data processing with data.table</a></li>
<li class="chapter" data-level="4.7" data-path="efficient-workflow.html"><a href="efficient-workflow.html#publication"><i class="fa fa-check"></i><b>4.7</b> Publication</a><ul>
<li class="chapter" data-level="4.7.1" data-path="efficient-workflow.html"><a href="efficient-workflow.html#dynamic-documents-with-knitr"><i class="fa fa-check"></i><b>4.7.1</b> Dynamic documents with knitr</a></li>
<li class="chapter" data-level="4.7.2" data-path="efficient-workflow.html"><a href="efficient-workflow.html#r-packages"><i class="fa fa-check"></i><b>4.7.2</b> R packages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="efficient-collaboration.html"><a href="efficient-collaboration.html"><i class="fa fa-check"></i><b>5</b> Efficient collaboration</a></li>
<li class="chapter" data-level="6" data-path="efficient-programming.html"><a href="efficient-programming.html"><i class="fa fa-check"></i><b>6</b> Efficient programming</a><ul>
<li class="chapter" data-level="6.1" data-path="efficient-programming.html"><a href="efficient-programming.html#data-types"><i class="fa fa-check"></i><b>6.1</b> Data types</a><ul>
<li class="chapter" data-level="6.1.1" data-path="efficient-programming.html"><a href="efficient-programming.html#vectors"><i class="fa fa-check"></i><b>6.1.1</b> Vectors</a></li>
<li class="chapter" data-level="6.1.2" data-path="efficient-programming.html"><a href="efficient-programming.html#factors"><i class="fa fa-check"></i><b>6.1.2</b> Factors</a></li>
<li class="chapter" data-level="6.1.3" data-path="efficient-programming.html"><a href="efficient-programming.html#data-frames"><i class="fa fa-check"></i><b>6.1.3</b> Data frames</a></li>
<li class="chapter" data-level="6.1.4" data-path="efficient-programming.html"><a href="efficient-programming.html#matrix"><i class="fa fa-check"></i><b>6.1.4</b> Matrix</a></li>
<li class="chapter" data-level="6.1.5" data-path="efficient-programming.html"><a href="efficient-programming.html#S3"><i class="fa fa-check"></i><b>6.1.5</b> S3 objects</a></li>
<li class="chapter" data-level="6.1.6" data-path="efficient-programming.html"><a href="efficient-programming.html#efficient-data-structures"><i class="fa fa-check"></i><b>6.1.6</b> Efficient data structures</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="efficient-programming.html"><a href="efficient-programming.html#good-programming-techniques"><i class="fa fa-check"></i><b>6.2</b> Good programming techniques</a><ul>
<li class="chapter" data-level="6.2.1" data-path="efficient-programming.html"><a href="efficient-programming.html#general-tips"><i class="fa fa-check"></i><b>6.2.1</b> General tips</a></li>
<li class="chapter" data-level="6.2.2" data-path="efficient-programming.html"><a href="efficient-programming.html#caching-variables"><i class="fa fa-check"></i><b>6.2.2</b> Caching variables</a></li>
<li class="chapter" data-level="6.2.3" data-path="efficient-programming.html"><a href="efficient-programming.html#function-closures"><i class="fa fa-check"></i><b>6.2.3</b> Function closures</a></li>
<li class="chapter" data-level="6.2.4" data-path="efficient-programming.html"><a href="efficient-programming.html#vectorised-code"><i class="fa fa-check"></i><b>6.2.4</b> Vectorised code</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="efficient-programming.html"><a href="efficient-programming.html#parallel-computing"><i class="fa fa-check"></i><b>6.3</b> Parallel computing</a><ul>
<li class="chapter" data-level="6.3.1" data-path="efficient-programming.html"><a href="efficient-programming.html#parallel-versions-of-apply-functions"><i class="fa fa-check"></i><b>6.3.1</b> Parallel versions of apply functions</a></li>
<li class="chapter" data-level="6.3.2" data-path="efficient-programming.html"><a href="efficient-programming.html#example-parallel-bootstraping"><i class="fa fa-check"></i><b>6.3.2</b> Example: parallel bootstraping</a></li>
<li class="chapter" data-level="6.3.3" data-path="efficient-programming.html"><a href="efficient-programming.html#process-forking"><i class="fa fa-check"></i><b>6.3.3</b> Process forking</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="efficient-programming.html"><a href="efficient-programming.html#the-byte-compiler"><i class="fa fa-check"></i><b>6.4</b> The byte compiler</a><ul>
<li class="chapter" data-level="6.4.1" data-path="efficient-programming.html"><a href="efficient-programming.html#example-the-mean-function"><i class="fa fa-check"></i><b>6.4.1</b> Example: the mean function</a></li>
<li class="chapter" data-level="6.4.2" data-path="efficient-programming.html"><a href="efficient-programming.html#compiling-code"><i class="fa fa-check"></i><b>6.4.2</b> Compiling code</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="efficient-rcpp.html"><a href="efficient-rcpp.html"><i class="fa fa-check"></i><b>7</b> Efficient Rcpp</a></li>
<li class="chapter" data-level="8" data-path="efficient-memory.html"><a href="efficient-memory.html"><i class="fa fa-check"></i><b>8</b> Efficient Memory</a></li>
<li class="chapter" data-level="9" data-path="efficient-learning.html"><a href="efficient-learning.html"><i class="fa fa-check"></i><b>9</b> Efficient Learning</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Efficient R programming</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="efficient-workflow" class="section level1">
<h1><span class="header-section-number">4</span> Efficient workflow</h1>
<p>Efficient programming is an important and sometimes vital skill for generating the correct result, on time. Yet coding is only one part of a wider skillset needed for successful project outcomes which involve R. In this context we define ‘workflow’ as the sum of practices, habits and systems that enable productivity.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> To some extent workflow is about personal preferences. Everyone’s mind works differently so the most appropriate workflow varies from person to person and from one project to the next. Project management practices will also vary depending the scale and type of the project.</p>
<p>Scale is a vital consideration because the importance of project management increases in a non linear fashion with the number of people involved. Writing a ‘one-off’ R script requires no project management. Working with several developers to deliver a mission critical application for central government requires regular meetings, division of labour and a project management system for tracking progress, issues and priorities.<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a></p>
<p>Project management structures also depend on the <em>type</em> of project. The typology below (thanks to Richard Cotton) demonstrate the links between project type and project management requirements.</p>
<ul>
<li><em>Data analysis</em>. Here you are trying to explore datasets to discover something interesting/answer some questions. The emphasis is on speed of manipulating your data to generate interest results. Formality is less important in this type of project. Sometimes this analysis project may only be part of a larger project (the data may have to be created in a lab, for example). How the data analysts interact with the rest of the team may be as important for the project’s success as how they interact with each other.</li>
<li><em>Package creation</em>. Here you want to create code that can be reused across projects, possibly by people whose use case you don’t know (if you make it publicly available). The emphasis in this case will be on clarity of user interface and documentation, meaning style and code review are important. Robustness and testing are important in this type of project too.</li>
<li><em>Reporting and publishing</em>. Here you are writing a report or journal paper or book. The level of formality varies depending upon the audience, but you have additional worries like how much code it takes to arrive at the conclusions, and how much output does the code create.</li>
<li><em>Software applications</em>. This could range from a simple Shiny app to R being embedded in the server of a much larger piece of software. Either way, since there is limited opportunity for human interaction, the emphasis is on robust code and gracefully dealing with failure.</li>
</ul>
<p>Based on these observations we recommend trying different working practices to discover which works best for you and the teams you work with.<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a></p>
<p>There are, however, concrete steps that can be taken to improve workflow in most projects that involve R programming. Learning them will, in the long-run, improve productivity and reproducibility. With these motivations in mind, the purpose of this chapter is simple: to highlight some key ingredients of an efficient R workflow. It builds on the concept of an R/RStudio <em>project</em>, introduced in Chapter 2, and is ordered chronologically throughout the stages involved in a typical project’s lifespan, from its inception to publication:</p>
<ul>
<li><p>Project planning. This should happen before any code has been written, to avoid time wasted using a mistaken analysis strategy.</p></li>
<li><p>Package selection. After planning your project you should identify which packages are most suitable to get the work done quickly and effectively. With rapid increases in the number and performance of packages (<code>*_join</code> from <strong>dplyr</strong>, for example, is often more appropriate than <code>merge</code>), it is more important than ever to consider the range of options at the outset.</p></li>
<li><p>Importing data. This can depend on external packages and represent a time-consuming and computational bottle-neck that prevents progress.</p></li>
<li><p>Tidying data. This critical stage results in datasets that are convenient for analysis and processing, with implications for the efficiency of all subsequent stages <span class="citation">(Wickham <a href="#ref-Wickham_2014">2014</a><a href="#ref-Wickham_2014">b</a>)</span>.</p></li>
<li><p>Data processing. This stage involves manipulating data to help answer hypotheses and draw conclusions. The focus of this section is on <strong>dplyr</strong> and <strong>data.table</strong>, which make data analysis code fast to type and fast to run.</p></li>
<li><p>Publication. This final stage is relevant if you want your R code to be useful for others in the long term. To this end Section <a href="efficient-workflow.html#publication">4.7</a> touches on documentation using knitr and the much stricter approach to code publication of package development.</p></li>
</ul>
<div id="project-planning" class="section level2">
<h2><span class="header-section-number">4.1</span> Project planning</h2>
<p>Good programmers embarking on a complex project will rarely just start typing code. Instead, they will plan the steps needed to complete the task as efficiently as possible: “smart preparation minimizes work” <span class="citation">(Berkun <a href="#ref-berkun2005art">2005</a>)</span>. Although search engines are useful for identifying the appropriate strategy, the trail-and-error approach — typing code at random and Googling the inevitable error messages — is usually highly <em>inefficient</em>. Strategic thinking is necessary.</p>
<p>The best place to start may in fact be pen and blank sheet of paper, allowing you to sketch out your ideas before you begin. Project planning is a creative process not always well-suited to the linear logic of computing.<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a> It involves considering the project’s aims in the context of available resources (e.g. computational and programmer resources), project scope, timescales and suitable software. And these things should be considered together. To take one example, is it worth the investment of time needed to learn a particular R package which is not essential to completing the project but which will make the code run faster? Does it make more sense to hire another programmer or invest in more computational resources to complete an urgent deadline?</p>
<p>Minutes spent thinking through such issues before writing a single line can save hours in the future. This is emphasised in books such as <span class="citation">Berkun (<a href="#ref-berkun2005art">2005</a>)</span> and <span class="citation">PMBoK (<a href="#ref-PMBoK_2000">2000</a>)</span> and useful online resources such those by <a href="http://teamgantt.com/guide-to-project-management/">teamgantt.com</a> and <a href="http://www.lasa.org.uk/uploads/publications/ictpublications/computanews_guides/lcgpm.pdf">lasa.org.uk</a>, which focus exclusively on project planning. This section is not intended to replace such guides. Instead, the aim here is to condense some of the most important lessons from this literature in the context of typical R projects (i.e. which involve data analysis, modelling and visualisation).</p>
<div id="chunking-your-work" class="section level3">
<h3><span class="header-section-number">4.1.1</span> ‘Chunking’ your work</h3>
<p>Once a project overview has been devised and stored, in mind (for small projects, if you trust that as storage medium!) or written, a plan with a time-line can be drawn-up. The up-to-date visualisation of this plan can be a powerful reminder to yourself and collaborators of progress on the project so far. More importantly the timeline provides an overview of what needs to be done next. Setting start dates and deadlines for each task will help prioritise the work and ensure you are on track. Breaking a large project into smaller chunks is highly recommended, making huge, complex tasks more achievable and modular <span class="citation">PMBoK (<a href="#ref-PMBoK_2000">2000</a>)</span>. ‘Chunking’ the work will also make collaboration easier, as we shall see in Chapter 5.</p>
<div class="figure"><span id="fig:phases"></span>
<img src="_main_files/figure-html/phases-1.png" alt="Schematic illustrations of key project phases and levels of activity over time, based on @PMBoK_2000." width="672" />
<p class="caption">
Figure 4.1: Schematic illustrations of key project phases and levels of activity over time, based on <span class="citation">PMBoK (<a href="#ref-PMBoK_2000">2000</a>)</span>.
</p>
</div>
<p>The tasks that a project should be split into will depend the nature of the work and the phases illustrated in Figure <a href="efficient-workflow.html#fig:phases">4.1</a> represent a rough starting point, not a template and the ‘programming’ phase will usually need to be split into at least ‘data tidying’, ‘processing’, and ‘visualisation’.</p>
</div>
<div id="smart" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Making your workflow SMART</h3>
<p>A more rigorous (but potentially onerous) way to project plan is to divide the work into a series of objectives and tracking their progress throughout the project’s duration. One way to check if an objective is appropriate for action and review is by using the SMART criteria.</p>
<ul>
<li>Specific: is the objective clearly defined and self-contained?</li>
<li>Measurable: is there a clear indication of its completion?</li>
<li>Attainable: can the target be achieved?</li>
<li>Realistic: have sufficient resources been allocated to the task?</li>
<li>Time-bound: is there an associated completion date or milestone?</li>
</ul>
<p>If the answer to each of these questions is ‘yes’, the task is likely to be suitable to include in the project’s plan. Note that this does not mean all project plans need to be uniform. A project plan can take many forms, including a short document, a Gantt chart (see Figure <a href="efficient-workflow.html#fig:timeline">4.2</a> or simply a clear vision of the project’s steps in mind.</p>
<div class="figure"><span id="fig:timeline"></span>
<img src="figures/DiagrammeR-gantt-book.png" alt="A Gantt chart created using **DiagrammeR** illustrating the steps needed to complete this book at an early stage of its development."  />
<p class="caption">
Figure 4.2: A Gantt chart created using <strong>DiagrammeR</strong> illustrating the steps needed to complete this book at an early stage of its development.
</p>
</div>
</div>
<div id="r-packages-for-planning" class="section level3">
<h3><span class="header-section-number">4.1.3</span> R packages for planning</h3>
<p>A number of R packages can assist with this process of formalising and visualising the project plan, including:<a href="#fn12" class="footnoteRef" id="fnref12"><sup>12</sup></a></p>
<ul>
<li><p>the <a href="https://cran.r-project.org/web/packages/plan/"><strong>plan</strong></a> package, which provides basic tools to create burndown charts (which concisely show whether a project is on-time or not) and Gantt charts.</p></li>
<li><p><a href="https://cran.r-project.org/web/packages/plotrix/index.html"><strong>plotrix</strong></a>, a general purpose plotting package, provides basic Gantt chart plotting functionality. Enter <code>example(gantt.chart)</code> for details.</p></li>
<li><p><a href="http://rich-iannone.github.io/DiagrammeR/"><strong>DiagrammeR</strong></a>, a new package for creating network graphs and other schematic diagrams in R. This package provides an R interface to simple flow-chart file formats such as <a href="https://github.com/knsv/mermaid">mermaid</a> and <a href="https://github.com/ellson/graphviz">GraphViz</a>.</p></li>
</ul>
<p>The small example below (which provides the basis for creating charts like Figure <a href="efficient-workflow.html#fig:timeline">4.2</a> illustrates how <strong>DiagrammeR</strong> can take simple text inputs to create informative up-to-date Gantt charts. Such charts can greatly help with the planning and task management of long and complex R projects, as long as they do not take away valuable programming time from core project objectives. {#DiagrammeR}</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;DiagrammeR&quot;</span>) <span class="co"># load the necessary package</span>

<span class="co"># define the Gantt chart and plot the result (not shown)</span>
<span class="kw">mermaid</span>(<span class="st">&quot;gantt</span>
<span class="st">        Section Initiation</span>
<span class="st">        Planning           :a1, 2016-01-01, 10d</span>
<span class="st">        Data processing    :after a1  , 30d&quot;</span>)</code></pre></div>
<p>In the above code <code>gantt</code> defines the subsequent data layout. <code>Section</code> refers to the project’s section (useful for large projects, with milestones) and each new line refers to a discrete task. <code>Planning</code>, for example, has the code <code>a</code>, begins on the first day of 2016 and lasts for 10 days. See <a href="http://knsv.github.io/mermaid/gantt.html">knsv.github.io/mermaid/gantt.html</a> for more detailed documentation.</p>
</div>
<div id="exercises-8" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Exercises</h3>
<ol style="list-style-type: decimal">
<li><p>What are the three most important work ‘chunks’ of your current R project?</p></li>
<li><p>What is the meaning of ‘SMART’ objectives (see <a href="efficient-workflow.html#smart">Making your workflow SMART</a>).</p></li>
<li><p>Run the <a href="#DiagrammeR">code chunk</a> at the end of this section to see the output.</p></li>
<li><p>Bonus exercise: modify this code to create a basic Gantt chart of an R project you are working on.</p></li>
</ol>
</div>
</div>
<div id="pkgs" class="section level2">
<h2><span class="header-section-number">4.2</span> Package selection</h2>
<p>A good example of the importance of prior planning to minimise effort is package selection. An inefficient, poorly supported or simply outdated package can waste hours. When a more appropriate alternative is available this waste can be prevented by prior planning. There are many poor packages on CRAN and much duplication so it’s easy to go wrong. Just because a certain package <em>can</em> solve a particular problem, doesn’t mean that it <em>should</em>.</p>
<p>However, used well, packages can greatly improve productivity. Due to the conservative nature of base R development, which rightly prioritises stability over innovation, much of the innovation and performance gains in the ‘R ecosystem’ has occurred in recent years in the packages. The increased ease of package development <span class="citation">(Wickham <a href="#ref-Wickham_2015">2015</a>)</span> and interfacing with other languages <span class="citation">(e.g. Eddelbuettel et al. <a href="#ref-Eddelbuettel_2011">2011</a>)</span> has accelerated their number, quality and efficiency. An additional factor has been the growth in collaboration and peer review in package development, driven by code-sharing websites such as GitHub and online communities such as <a href="https://ropensci.org/">ROpenSci</a> for peer reviewing code.</p>
<p>Performance, stability and ease of use should be high on the priority list when choosing which package to use. Another more subtle factor is that some packages work better together than others. The ‘R package ecosystem’ is composed of interrelated package. Knowing something of these inter-dependencies can help select a ‘package suite’ when the project demands a number of diverse yet interrelated programming tasks. The ‘hadleyverse’, for example, contains many interrelated packages that work well together, such as <strong>readr</strong>, <strong>tidyr</strong>, and <strong>dplyr</strong>.<a href="#fn13" class="footnoteRef" id="fnref13"><sup>13</sup></a> These may be used together to read-in, tidy and then process the data, as outlined in the subsequent sections.</p>
<p>There is no ‘hard and fast’ rule about which package you should use and new packages are emerging all the time. The ultimate test will be empirical evidence: does it get the job done on your data? However, the following criteria should provide a good indication of whether a package is worth an investment of your precious time, or even installing on your computer:</p>
<ul>
<li><p><strong>Is it mature?</strong> The more time a package is available, the more time it will have for obvious bugs to be ironed out. The age of a package on CRAN can be seen from its Archive page on CRAN. We can see from <a href="https://cran.r-project.org/src/contrib/Archive/ggplot2/">cran.r-project.org/src/contrib/Archive/ggplot2/</a>, for example, that <strong>ggplot2</strong> was first released on the 10<sup>th</sup> June 2007 and that it has had 28 releases. The most recent of these at the time of writing was <strong>ggplot2</strong> 2.0.0: reaching 1 or 2 in the first digit of package versions is usually an indication from the package author that the package has reached a high level of stability.</p></li>
<li><p><strong>Is it actively developed?</strong> It is a good sign if packages are frequently updated. A frequently updated package will have its latest version ‘published’ recently on CRAN. The CRAN package page for <strong>ggplot2</strong>, for example, said <code>Published: 2015-12-18</code>, less than a month old at the time of writing.</p></li>
<li><p><strong>Is it well documented?</strong> This is not only an indication of how much thought, care and attention has gone into the package. It also has a direct impact on its ease of use. Using a poorly documented package can be inefficient due to the hours spent trying to work out how to use it! To check if the package is well documented, look at the help pages associated with its key functions (e.g. <code>?ggplot</code>), try the examples (e.g. <code>example(ggplot)</code>) and search for package vignettes (e.g. <code>vignette(package = &quot;ggplot2&quot;)</code>).</p></li>
<li><p><strong>Is it well used?</strong> This can be seen by searching for the package name online. Most packages that have a strong user base will produce thousands of results when typed into a generic search engine such as Google’s. More specific (and potentially useful) indications of use will narrow down the search to particular users. A package widely used by the programming community will likely visible GitHub. At the time of writing a search for <a href="https://github.com/search?utf8=%E2%9C%93&amp;q=ggplot2"><strong>ggplot2</strong></a> on GitHub yielded over 400 repositories and almost 200,000 matches in committed code! Likewise, a package that has been adopted for use in academia will tend to be mentioned in Google Scholar (again, <strong>ggplot2</strong> scores extremely well in this measure, with over 5000 hits).</p></li>
</ul>
<p>An article in <a href="http://simplystatistics.org/2015/11/06/how-i-decide-when-to-trust-an-r-package/">simplystats</a> discusses this issue with reference to the proliferation of GitHub packages (those that are not available on CRAN). In this context well-regarded and experienced package creators and ‘indirect data’ such as amount of GitHub activity are also highlighted as reasons to trust a package.</p>
</div>
<div id="importing-data" class="section level2">
<h2><span class="header-section-number">4.3</span> Importing data</h2>
<p>Before reading in data, it is worth considering a general principle for reproducible data management: never modify raw data files. Raw data should be seen as read-only, and contain information about its provenance. Keeping the original file name and including a comment about its origin are a couple of ways to improve reproducibility, even when the data are not publicly available. This is illustrated below with functions <code>download.file</code><a href="#fn14" class="footnoteRef" id="fnref14"><sup>14</sup></a> and <code>unzip</code> to download and unzip the dataset. This illustrates how R can automate processes that are often performed manually, e.g. through the graphical user interface of a web browser. The result of the code below is data stored neatly in the <code>data</code> directory ready to be read-in (note part of the dataset is also stored in the <strong>efficient</strong> package).</p>
<div class="rmdnote">
<p>
The data downloaded below is a multi-table dataset on Dutch naval expeditions used with permission from the CWI Database Architectures Group and described more fully at <a href="https://www.monetdb.org/Documentation/UserGuide/MonetDB-R">monetdb.org</a>. From this dataset we primarily use the ‘voyages’ table with lists Dutch shipping expeditions by their date of departure.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">url =<span class="st"> &quot;https://www.monetdb.org/sites/default/files/voc_tsvs.zip&quot;</span>
<span class="kw">download.file</span>(url, <span class="st">&quot;voc_tsvs.zip&quot;</span>) <span class="co"># download file</span>
<span class="kw">unzip</span>(<span class="st">&quot;voc_tsvs.zip&quot;</span>, <span class="dt">exdir =</span> <span class="st">&quot;data&quot;</span>) <span class="co"># unzip files</span>
<span class="kw">file.remove</span>(<span class="st">&quot;voc_tsvs.zip&quot;</span>) <span class="co"># tidy up by removing the zip file</span></code></pre></div>
<div class="rmdtip">
<p>
To avoid the file download stage, many functions for reading in data can accept urls and read directly from the internet. This is illustrated below for <code>read.csv()</code>:
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">url =<span class="st"> &quot;https://www.osha.gov/dep/fatcat/FatalitiesFY10.csv&quot;</span>
df =<span class="st"> </span><span class="kw">read.csv</span>(url)</code></pre></div>
<p>There are now many R packages to assist with the download and import of data. The organisation <a href="https://ropensci.org/">ROpenSci</a> supports a number of these. The example below illustrates this using the WDI package (not supported by ROpenSci) which accesses the World Bank’s World Development Indicators:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;WDI&quot;</span>) <span class="co"># load the WDI library (must be installed)</span>
<span class="kw">WDIsearch</span>(<span class="st">&quot;CO2&quot;</span>) <span class="co"># search for data on a topic</span>
df =<span class="st"> </span><span class="kw">WDI</span>(<span class="dt">indicator =</span> <span class="st">&quot;EN.CO2.TRAN.ZS&quot;</span> ) <span class="co"># import data</span></code></pre></div>
<p>There will be situations where you cannot download the data directly or when the data cannot be made available. In this case, simply providing a comment relating to the data’s origin (e.g. <code># Downloaded from http://example.com</code>) before referring to the dataset can greatly improve the utility of the code to yourself and others.</p>
<div id="fread" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Fast data reading</h3>
<p>There is often more than one way to read data into R. Even a simple <code>.csv</code> file can be imported using a range of methods, with implications for computational efficiency. This section looks at three approaches: base R’s plain text reading functions such as <code>read.delim</code>, which are derived from <code>read.table</code>; the <strong>data.table</strong> approach, which uses the function <code>fread</code>; and the newer <strong>readr</strong> package which provides <code>read_csv</code> and other <code>read_</code> functions such as <code>read_tsv</code>.</p>
<div class="rmdnote">
<p>
Note that a function ‘derived from’ another in this context means that it calls another function. The functions such as <code>read.csv</code> and <code>read.delim</code> in fact are <em>wrappers</em> for the more generic function <code>read.table</code>. This can be seen in the source code of <code>read.csv</code>, for example, which shows that the function is roughly the equivalent of <code>read.table(file, header = TRUE, sep = “,”</code>.
</p>
</div>
<p>Although this section is focussed on reading text files, it demonstrate the wider principle that the speed and flexibility advantages of additional read functions can be offset by the disadvantages of addition package dependency (in terms of complexity and maintaining the code) for small datasets. The real benefits kick in on large datasets. Of course, there are some data types that <em>require</em> a certain package to load in R: the readstata13 package, for example, was developed solely to read in <code>.dta</code> files generated by versions of Stata 13 and above.</p>
<p>Figure <a href="efficient-workflow.html#fig:readr-vs-base">4.3</a> demonstrates that the relative performance gains of the <strong>data.table</strong> and <strong>readr</strong> approaches increase with data size, especially so for data with many rows. Below around 1 MB <code>read.delim</code> is actually <em>faster</em> than <code>read_csv</code> while <code>fread</code> is much faster than both, although these savings are likely to be inconsequential for such small datasets.</p>
<p>For files beyond 100 MB in size <code>fread</code> and <code>read_csv</code> can be expected to be around <em>5 times faster</em> than <code>read.delim</code>. This efficiency gain may be inconsequential for a one-off file of 100 MB running on a fast computer (which still take less than a minute with <code>read.csv</code>), but could represent an important speed-up if you frequently load large text files.</p>
<div class="figure"><span id="fig:readr-vs-base"></span>
<img src="_main_files/figure-html/readr-vs-base-1.png" alt="Benchmarks of base, data.table and readr functions for reading csv files. The facets ranging from 2 to 200 represent the number of columns." width="672" />
<p class="caption">
Figure 4.3: Benchmarks of base, data.table and readr functions for reading csv files. The facets ranging from 2 to 200 represent the number of columns.
</p>
</div>
<p>When tested on a large (4 GB) .csv file it was found that <code>fread</code> and <code>read_csv</code> were almost identical in load times and that <code>read.csv</code> took around 5 times longer. This consumed more than 10 GB of RAM, making it unsuitable to run on many computers (see Section <a href="efficient-hardware.html#ram">3.2</a> for more on memory). Note that both <strong>readr</strong> and base methods can be made faster by pre-specifying the column types at the outset, as illustrated in <a href="efficient-workflow.html#fig:readr-vs-base">4.3</a> and described in the help files.</p>
<!-- Idea: test the functions on text data -->
<p>In some cases with R programming there is a trade-off between speed and robustness. This is illustrated below with reference to differences in how <strong>readr</strong>, <strong>data.table</strong> and base R approaches handle unexpected values. Table <a href="efficient-workflow.html#tab:voyages">4.1</a> shows that <code>read_tsv</code> is around 3 times faster, re-enforcing the point that the benefits of efficient functions increase with dataset size (made with Figure <a href="efficient-workflow.html#fig:readr-vs-base">4.3</a>). This is a small (1 MB) dataset: the relative difference between <code>fread</code> and <code>read_</code> functions will tend to decrease as dataset size increases.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;microbenchmark&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;readr&quot;</span>)
<span class="kw">library</span>(<span class="st">&quot;data.table&quot;</span>)
fname =<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/voc_voyages.tsv&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;efficient&quot;</span>)
res_v =<span class="st"> </span><span class="kw">microbenchmark</span>(<span class="dt">times =</span> <span class="dv">10</span>,
  <span class="dt">base_read =</span> voyages_base &lt;-<span class="st"> </span><span class="kw">read.delim</span>(fname),
  <span class="dt">readr_read =</span> voyages_readr &lt;-<span class="st"> </span><span class="kw">read_tsv</span>(fname),
  <span class="dt">dt_fread =</span> voyages_dt &lt;-<span class="st"> </span><span class="kw">fread</span>(fname))</code></pre></div>
<table>
<caption><span id="tab:voyages">Table 4.1: </span>Execution time of base, <strong>readr</strong> and <strong>data.table</strong> functions for reading in a 1 MB dataset relative to the mean execution time of <code>fread</code>, around 0.02 seconds on a modern computer.</caption>
<thead>
<tr class="header">
<th align="left">Function</th>
<th align="right">min</th>
<th align="right">mean</th>
<th align="right">max</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">base_read</td>
<td align="right">10.7</td>
<td align="right">11.1</td>
<td align="right">11.4</td>
</tr>
<tr class="even">
<td align="left">readr_read</td>
<td align="right">3.4</td>
<td align="right">4.7</td>
<td align="right">13.5</td>
</tr>
<tr class="odd">
<td align="left">dt_fread</td>
<td align="right">1.0</td>
<td align="right">1.0</td>
<td align="right">1.0</td>
</tr>
</tbody>
</table>
<p>The benchmark above produces warning messages (not shown) for the <code>read_tsv</code> and <code>fread</code> functions but not the slowest base function <code>read.delim</code>. An exploration of these functions can shed light on the speed/robustness trade-off.</p>
<ul>
<li>The <strong>readr</strong> function <code>read_csv</code> generates a warning for row 2841 in the <code>built</code> variable. This is because <code>read_*()</code> decides what class each variable is based on the first 1000 rows, rather than all rows, as base <code>read.*</code> functions do.</li>
</ul>
<p>As illustrated by printing the result for the row which generated a warning, the <code>read_tsv</code> output is more sensible than the <code>read.delim</code> output: <code>read.delim</code> coerced the date field into a factor based on a single entry which is a text. <code>read_tsv</code> coerced the variable into a numeric vector, as illustrated below.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(voyages_base$built) <span class="co"># coerced to a factor</span>
<span class="co">#&gt; [1] &quot;factor&quot;</span>
<span class="kw">class</span>(voyages_readr$built) <span class="co"># numeric based on first 1000 rows</span>
<span class="co">#&gt; [1] &quot;numeric&quot;</span>
voyages_base$built[<span class="dv">2841</span>] <span class="co"># contains the text responsible for coercion</span>
<span class="co">#&gt; [1] 1721-01-01</span>
<span class="co">#&gt; 182 Levels:  1 784 1,86 1135 1594 1600 1612 1613 1614 1615 1619 ... taken 1672</span>
voyages_readr$built[<span class="dv">2841</span>] <span class="co"># an NA: text cannot be converted to numeric</span>
<span class="co">#&gt; [1] NA</span></code></pre></div>
<ul>
<li>The <strong>data.table</strong> function <code>fread</code> generates 5 warning messages stating that columns 2, 4, 9, 10 and 11 were <code>Bumped to type character on data row ...</code>, with the offending rows printed in place of <code>...</code>. Instead of changing the offending values to <code>NA</code>, as <strong>readr</strong> does for the <code>built</code> column (9), <code>fread</code> automatically converts any columns it thought of as numeric into characters.</li>
</ul>
<p>To summarise, the differences between base, <strong>readr</strong> and <strong>data.table</strong> functions for reading in data go beyond code execution times. The functions <code>read_csv</code> and <code>fread</code> boost speed partially at the expense of robustness because they decide column classes based on a small sample of available data. The similarities and differences between the approaches are summarised for the Dutch shipping data (described in a note at the beginning of this section) in Table <a href="efficient-workflow.html#tab:colclasses">4.2</a>.</p>
<table>
<caption><span id="tab:colclasses">Table 4.2: </span>Execution time of base, <strong>readr</strong> and <strong>data.table</strong> functions for reading in a 1 MB dataset</caption>
<thead>
<tr class="header">
<th align="left">Function</th>
<th align="left">number</th>
<th align="left">boatname</th>
<th align="left">built</th>
<th align="left">departure_date</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">base_read</td>
<td align="left">integer</td>
<td align="left">factor</td>
<td align="left">factor</td>
<td align="left">factor</td>
</tr>
<tr class="even">
<td align="left">readr_read</td>
<td align="left">integer</td>
<td align="left">character</td>
<td align="left">numeric</td>
<td align="left">Date</td>
</tr>
<tr class="odd">
<td align="left">dt_fread</td>
<td align="left">integer</td>
<td align="left">character</td>
<td align="left">character</td>
<td align="left">character</td>
</tr>
</tbody>
</table>
<p>Table <a href="efficient-workflow.html#tab:colclasses">4.2</a> shows 4 main similarities and differences between the three read types of read function:</p>
<ul>
<li>For uniform data such as the ‘number’ variable in Table <a href="efficient-workflow.html#tab:colclasses">4.2</a>, all reading methods yield the same result (integer in this case).</li>
<li>For columns that are obviously characters such as ‘boatname’, the base method results in factors (unless <code>stringsAsFactors</code> is set to <code>TRUE</code>) whereas <code>fread</code> and <code>read_csv</code> functions return characters.</li>
<li>For columns in which the first 1000 rows are of one type but which contain anomalies, such as ‘built’ and ‘departure_data’ in the shipping example, <code>fread</code> coerces the result to characters. <code>read_csv</code> and siblings, by contrast, keep the class that is correct for the first 1000 rows and sets the anomalous records to <code>NA</code>. This is illustrated in <a href="efficient-workflow.html#tab:colclasses">4.2</a>, where <code>read_tsv</code> produces a <code>numeric</code> class for the ‘built’ variable, ignoring the non numeric text in row 2841.</li>
<li><code>read_*</code> functions generate objects of class <code>tbl_df</code>, an extension of the <code>data.frame</code>, as discussed in Section <a href="efficient-workflow.html#dplyr">4.5</a>. <code>fread</code> generates objects of class <code>data.table</code>. These can be used as standard data frames but differ subtly in their behaviour.</li>
</ul>
<p>The wider point associated with these tests is that functions that save time can also lead to additional considerations or complexities your workflow. Taking a look at what is going on ‘under the hood’ of fast functions to increase speed, as we have done in this section, can help understand the knock-on consequences of choosing fast functions over slower functions from base R.</p>
</div>
<div id="preprocessing-outside-r" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Preprocessing outside R</h3>
<p>There are circumstances when datasets become too large to read directly into R. Reading in 4 GB text file using the functions tested above, for example, consumed all available RAM on an 16 GB machine! To overcome the limitation that R reads all data directly into RAM, external <em>stream processing</em> tools can be used to preprocess large text files. The following command, using the shell command <code>split</code>, for example, would break a large multi GB file many one GB chunks, each of which is more manageable for R:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">split</span> -b100m bigfile.csv</code></pre></div>
<p>The result is a series of files, set to 100 MB each with the <code>-b100m</code> argument in the above code. By default these will be called <code>xaa</code>, <code>xab</code> and which could be read in <em>one chunk at a time</em> (e.g. using <code>read.csv</code>, <code>fread</code> or <code>read_csv</code>, described in the previous section) without crashing most modern computers.</p>
<p>Splitting a large file into individual chunks may allow it to be read into R. This is not an efficient way to import large datasets, however, because it results in a non-random sample of the data this way. A more efficient way to work with very large datasets is via databases.</p>
</div>
<div id="working-with-databases" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Working with databases</h3>
<p>Instead of loading all the data into RAM, as R does, databases query data from the hard-disk. This can allow a subset of a very large dataset to be defined and read into R quickly, without having to load it first.</p>
<p>R can connect to databases in a number of ways. The most mature of these is via the <strong>RODBC</strong> package, which sets up links to external databases using the Open Database Connectivity (ODBC) API. The functionality of <strong>RODBC</strong> is described in the package’s vignette, accessed with <code>vignette(&quot;RODBC&quot;)</code>. <strong>RODBC</strong> connects to ‘traditional’ databases such as MySQL, PostgreSQL, Oracle and SQLite.</p>
<p>The function used to set-up a connection to an external database with RODBC is <code>odbcConnect</code>, which takes Data Source Name (<code>dsn =</code>), User ID (<code>uid =</code>) and password (<code>pwd</code>) as required arguments.</p>
<div class="rmdtip">
<p>
Be sure never to release your password by entering it directly into the command. Instead, we recommend saving sensitive information such as database passwords and API keys in <code>.Renviron</code>, described in <span class="citation">(<span class="citeproc-not-found" data-reference-id="ref"><strong>???</strong></span>)</span>(renviron). Assuming you had saved your password as the environment variable <code>PSWRD</code>, you could enter <code>pwd = Sys.getenv(“PSWRD”)</code> to minimise the risk of exposing your password through accidentally releasing the code or your session history.
</p>
</div>
<p>Recently there has been a shift to the ‘noSQL’ approach for storing large datasets. This is illustrated by the emergence and uptake of software such as MongoDB and Apache Cassandra, which have R interfaces via packages <a href="https://cran.r-project.org/web/packages/mongolite/index.html">mongolite</a> and <a href="https://cran.r-project.org/web/packages/RJDBC/index.html">RJDBC</a>, which can connect to Apache Cassandra data stores and any source compliant with the Java Database Connectivity (JDBC) API.</p>
<p>MonetDB is a recent alternative to traditional and noSQL approaches which offers substantial efficiency advantages for handling large datasets <span class="citation">(Kersten et al. <a href="#ref-kersten2011researcher">2011</a>)</span>. A tutorial on the <a href="https://www.monetdb.org/Documentation/UserGuide/MonetDB-R">MonetDB website</a> provides an excellent introduction to handling databases from within R. A new development showcased in this tutorial is the ability to interact with databases using exactly the same syntax used to interact with R objects stored in RAM. This innovation was made possible by <strong>dplyr</strong>, an R library for data processing that aims to provide a unified ‘front end’ to perform a wide range of analysis task on datasets using a variety of ‘back ends’ which do the number crunching. This is one of the main advantages of <strong>dplyr</strong> (see Section <a href="efficient-workflow.html#dplyr">4.5</a>).</p>
</div>
</div>
<div id="tidying-data-with-tidyr" class="section level2">
<h2><span class="header-section-number">4.4</span> Tidying data with tidyr</h2>
<p>A key skill in data analysis is understanding the structure of datasets and being able to ‘reshape’ them. This is important from a workflow efficiency perspective: more than half of a data analyst’s time can be spent re-formatting datasets <span class="citation">(Wickham <a href="#ref-Wickham_2014">2014</a><a href="#ref-Wickham_2014">b</a>)</span>. Converting data into a ‘tidy’ form is also advantageous from a computational efficiency perspective: it is usually faster to run analysis and plotting commands on a few large vectors than many short vectors. This is illustrated by Tables <a href="efficient-workflow.html#tab:tpew">4.3</a> and <a href="efficient-workflow.html#tab:tpewt">4.4</a>, provided by <span class="citation">Wickham (<a href="#ref-Wickham_2014">2014</a><a href="#ref-Wickham_2014">b</a>)</span>.</p>
<p>These tables may look different, but they contain precisely the same information. Column names in the ‘flat’ form in Table <a href="efficient-workflow.html#tab:tpew">4.3</a> became a new variable in the ‘long’ form in Table <a href="efficient-workflow.html#tab:tpewt">4.4</a>. According to the concept of ‘tidy data’, the long form is correct. Note that ‘correct’ here is used in the context of data analysis and graphical visualisation. For tabular presentation the ‘wide’ or ‘untidy’ form may be better.</p>
<p>Tidy data has the following characteristics <span class="citation">(Wickham <a href="#ref-Wickham_2014">2014</a><a href="#ref-Wickham_2014">b</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li>Each variable forms a column.</li>
<li>Each observation forms a row.</li>
<li>Each type of observational unit forms a table.</li>
</ol>
<p>Because there is only one observational unit in the example (religions), it can be described in a single table. Large and complex datasets are usually represented by multiple tables, with unique identifiers or ‘keys’ to join them together <span class="citation">(Codd <a href="#ref-Codd1979">1979</a>)</span>.</p>
<p>Two common operations facilitated by <strong>tidyr</strong> are <em>gathering</em> and <em>splitting</em> columns.</p>
<ul>
<li>Gathering: this means making ‘wide’ tables ‘long’ by converting column names to a new variable. This is done is done with the function <code>gather</code> (the inverse of which is <code>spread</code>) , as illustrated in Table <a href="efficient-workflow.html#tab:tpew">4.3</a> and Table <a href="efficient-workflow.html#tab:tpewt">4.4</a> and in the code block below:</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;tidyr&quot;</span>)
raw =<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/pew.csv&quot;</span>) <span class="co"># read in the &#39;wide&#39; dataset</span>
<span class="kw">dim</span>(raw)
<span class="co">#&gt; [1] 18 10</span>
rawt =<span class="st"> </span><span class="kw">gather</span>(raw, Income, Count, -religion)
<span class="kw">dim</span>(rawt)
<span class="co">#&gt; [1] 162   3</span>
rawt[<span class="dv">1</span>:<span class="dv">3</span>,]
<span class="co">#&gt; Source: local data frame [3 x 3]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   religion Income Count</span>
<span class="co">#&gt;      (chr)  (chr) (int)</span>
<span class="co">#&gt; 1 Agnostic  &lt;$10k    27</span>
<span class="co">#&gt; 2  Atheist  &lt;$10k    12</span>
<span class="co">#&gt; 3 Buddhist  &lt;$10k    27</span></code></pre></div>
<div class="rmdtip">
<p>
Note that the dimensions of the data change from having 10 observations across 18 columns to 162 rows in only 3 columns. Note that when we print the object <code>rawt[1:3,]</code>, the class of each variable is given (<code>chr</code>, <code>fctr</code>, <code>int</code> refer to character, factor and integer classes, respectively). This is because <code>read_csv</code> uses the <code>tbl</code> class from the <strong>dplyr</strong> package (described below).
</p>
</div>
<table>
<caption><span id="tab:tpew">Table 4.3: </span>First 6 rows of the aggregated ‘pew’ dataset from Wickham (2014a) in an ‘untidy’ form.</caption>
<thead>
<tr class="header">
<th align="left">religion</th>
<th align="right">&lt;$10k</th>
<th align="right">$10–20k</th>
<th align="right">$20–30k</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Agnostic</td>
<td align="right">27</td>
<td align="right">34</td>
<td align="right">60</td>
</tr>
<tr class="even">
<td align="left">Atheist</td>
<td align="right">12</td>
<td align="right">27</td>
<td align="right">37</td>
</tr>
<tr class="odd">
<td align="left">Buddhist</td>
<td align="right">27</td>
<td align="right">21</td>
<td align="right">30</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:tpewt">Table 4.4: </span>First 3 and last rows of the ‘tidied’ Pew dataset.</caption>
<thead>
<tr class="header">
<th align="left">religion</th>
<th align="left">Income</th>
<th align="left">Count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Agnostic</td>
<td align="left">&lt;$10k</td>
<td align="left">27</td>
</tr>
<tr class="even">
<td align="left">Atheist</td>
<td align="left">&lt;$10k</td>
<td align="left">12</td>
</tr>
<tr class="odd">
<td align="left">Buddhist</td>
<td align="left">&lt;$10k</td>
<td align="left">27</td>
</tr>
<tr class="even">
<td align="left">…</td>
<td align="left">…</td>
<td align="left">…</td>
</tr>
<tr class="odd">
<td align="left">Unaffiliated</td>
<td align="left">&gt;150k</td>
<td align="left">258</td>
</tr>
</tbody>
</table>
<ul>
<li>Splitting: this means taking a variable that is really two variables combined and creating two separate columns from it. A classic example is age-sex variables (e.g. <code>m0-10</code> and <code>f0-15</code> to represent males and females in the 0 to 10 age band). Splitting such variables can be done with <code>separate</code>, as illustrated in Table <a href="efficient-workflow.html#tab:to-separate">4.5</a> and <a href="efficient-workflow.html#tab:separated">4.6</a>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">agesex =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;m0-10&quot;</span>, <span class="st">&quot;f0-10&quot;</span>) <span class="co"># create compound variable</span>
n =<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span>) <span class="co"># create a value for each observation</span>
df =<span class="st"> </span><span class="kw">data.frame</span>(agesex, n) <span class="co"># create a data frame</span>
<span class="kw">separate</span>(df, agesex, <span class="kw">c</span>(<span class="st">&quot;sex&quot;</span>, <span class="st">&quot;age&quot;</span>), <span class="dv">1</span>)
<span class="co">#&gt;   sex  age n</span>
<span class="co">#&gt; 1   m 0-10 3</span>
<span class="co">#&gt; 2   f 0-10 5</span></code></pre></div>
<table>
<caption><span id="tab:to-separate">Table 4.5: </span>Joined age and sex variables in one column</caption>
<thead>
<tr class="header">
<th align="left">agesex</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">m0-10</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">f0-10</td>
<td align="right">5</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:separated">Table 4.6: </span>Age and sex variables separated by the funtion <code>separate</code>.</caption>
<thead>
<tr class="header">
<th align="left">sex</th>
<th align="left">age</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">m</td>
<td align="left">0-10</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="left">f</td>
<td align="left">0-10</td>
<td align="right">5</td>
</tr>
</tbody>
</table>
<p>There are other tidying operations that <strong>tidyr</strong> can perform, as described in the package’s vignette (<code>vignette(&quot;tidy-data&quot;)</code>). Data manipulation is a large topic with major potential implications for efficiency, and there is an entire book on the subject <span class="citation">(Spector <a href="#ref-Spector_2008">2008</a>)</span>.</p>
</div>
<div id="dplyr" class="section level2">
<h2><span class="header-section-number">4.5</span> Data processing with dplyr</h2>
<p>Tidy data is easier and often faster to process than messy data. As with many aspects of R programming there are many ways to process a dataset, some more efficient than others. Following our own advice, we have selected a package for data processing early on (see Section <a href="efficient-workflow.html#pkgs">4.2</a>): <strong>dplyr</strong>. This package, which rougly means ‘data pliers’ or ‘plyr’ (another R package) for large datasets, has a number of advantages compared with base R and <strong>data.table</strong> approaches to data processing:</p>
<ul>
<li><strong>dplyr</strong> is fast to run and intuitive to type</li>
<li><strong>dplyr</strong> works well with tidy data, as described above</li>
<li><strong>dplyr</strong> works well with databases, providing efficiency gains on large datasets</li>
</ul>
<p>We will illustrate the functioning of <strong>dplyr</strong> with reference to a dataset on economic equality provided by the World Bank. This is loaded in the following code block:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;readr&quot;</span>)
fname =<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/world-bank-ineq.csv&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;efficient&quot;</span>)
idata =<span class="st"> </span><span class="kw">read_csv</span>(fname)
idata <span class="co"># print the dataset </span></code></pre></div>
<p><strong>dplyr</strong> is much faster than base implementations of various operations, but it has the potential to be even faster, as <em>parallelisation</em> is <a href="https://github.com/hadley/dplyr/issues/145">planned</a> and the <a href="https://github.com/hadley/multidplyr">multidplyr</a> package, a parallel backend for <strong>dplyr</strong>, is under development.</p>
<p>You should not be expecting to learn the <strong>dplyr</strong> package in one sitting: the package is large and can be seen as a language in its own right. Following the ‘walk before you run’ principle, we’ll start simple, by filtering and aggregating rows, building on the previous section on tidying data.</p>
<div id="renaming-columns" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Renaming columns</h3>
<p>Renaming data columns is a common task that can make writing code faster by using short, intuitive names. The <strong>dplyr</strong> function <code>rename()</code> makes this easy.</p>
<p>Note in this code block the variable name is surrounded by back-quotes (<code>). This allows R to refer to column names that are non-standard. Note also the syntax:</code>rename<code>takes the</code>data.frame<code>as the first object and then creates new variables by specifying</code>new_variable_name = original_name`.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>)
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;dplyr&#39;</span>
<span class="co">#&gt; The following objects are masked from &#39;package:data.table&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     between, last</span>
<span class="co">#&gt; The following objects are masked from &#39;package:stats&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     filter, lag</span>
<span class="co">#&gt; The following objects are masked from &#39;package:base&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     intersect, setdiff, setequal, union</span>
idata =<span class="st"> </span><span class="kw">rename</span>(idata, <span class="dt">Country =</span> <span class="st">`</span><span class="dt">Country Name</span><span class="st">`</span>)</code></pre></div>
<p>To rename multiple columns the variable names are simply separated by commas. The base R and <strong>dplyr</strong> way of doing this is illustrated for clarity.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The dplyr way (rename two variables)</span>
idata =<span class="st"> </span><span class="kw">rename</span>(idata,
 <span class="dt">top10 =</span> <span class="st">`</span><span class="dt">Income share held by highest 10% [SI.DST.10TH.10]</span><span class="st">`</span>,
 <span class="dt">bot10 =</span> <span class="st">`</span><span class="dt">Income share held by lowest 10% [SI.DST.FRST.10]</span><span class="st">`</span>)

<span class="co"># The base R way (rename five variables)</span>
<span class="kw">names</span>(idata)[<span class="dv">5</span>:<span class="dv">9</span>] =
<span class="st">  </span><span class="kw">c</span>(<span class="st">&quot;top10&quot;</span>, <span class="st">&quot;bot10&quot;</span>, <span class="st">&quot;gini&quot;</span>, <span class="st">&quot;b40_cons&quot;</span>, <span class="st">&quot;gdp_percap&quot;</span>)</code></pre></div>
<p>Now we have usefully renamed the object we save the result for future reference:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">saveRDS</span>(idata, <span class="st">&quot;data/idata-renamed.Rds&quot;</span>)</code></pre></div>
</div>
<div id="changing-column-classes" class="section level3">
<h3><span class="header-section-number">4.5.2</span> Changing column classes</h3>
<p>The <em>class</em> of R objects is critical to performance. If a class is incorrectly specified (e.g. if numbers are treated as factors or characters) this will lead to incorrect results. The class of all columns in a <code>data.frame</code> can be queried using the function <code>sapply()</code>, as illustrated below, with the inequality data loaded previously.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idata =<span class="st"> </span><span class="kw">readRDS</span>(<span class="st">&quot;data/idata-renamed.Rds&quot;</span>)
<span class="kw">sapply</span>(idata, class)
<span class="co">#&gt;      Country Country Code         Year    Year Code        top10 </span>
<span class="co">#&gt;  &quot;character&quot;  &quot;character&quot;    &quot;integer&quot;  &quot;character&quot;  &quot;character&quot; </span>
<span class="co">#&gt;        bot10         gini     b40_cons   gdp_percap </span>
<span class="co">#&gt;  &quot;character&quot;  &quot;character&quot;  &quot;character&quot;  &quot;character&quot;</span></code></pre></div>
<p>This shows that although we loaded the data correctly all columns are seen by R as characters. This means we cannot perform numerical calculations on the dataset: <code>mean(idata$gini)</code> fails.</p>
<p>Visual inspection of the data (e.g. via <code>View(idata)</code>) clearly shows that all columns except for 1 to 4 (“Country”, “Country Code”, “Year” and “Year Code”) should be numeric. We can re-assign the classes of the numeric variables one-by one:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idata$gini =<span class="st"> </span><span class="kw">as.numeric</span>(idata$gini)
<span class="co">#&gt; Warning: NAs introduced by coercion</span>
<span class="kw">mean</span>(idata$gini, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>) <span class="co"># now the mean is calculated</span>
<span class="co">#&gt; [1] 40.50363</span></code></pre></div>
<p>However, the purpose of programming languages is to <em>automate</em> tasks and reduce typing. The following code chunk re-classifies all of the numeric variables using <code>data.matrix()</code>, which converts a <code>data.frame</code> to a numeric <code>matrix</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">id =<span class="st"> </span><span class="dv">5</span>:<span class="dv">9</span> <span class="co"># column ids to change</span>
idata[id] =<span class="st"> </span><span class="kw">data.matrix</span>(idata[id])
<span class="kw">sapply</span>(idata, class)
<span class="co">#&gt;      Country Country Code         Year    Year Code        top10 </span>
<span class="co">#&gt;  &quot;character&quot;  &quot;character&quot;    &quot;integer&quot;  &quot;character&quot;    &quot;numeric&quot; </span>
<span class="co">#&gt;        bot10         gini     b40_cons   gdp_percap </span>
<span class="co">#&gt;    &quot;numeric&quot;    &quot;numeric&quot;    &quot;numeric&quot;    &quot;numeric&quot;</span></code></pre></div>
<p>As is so often the case with R, there are many ways to solve the problem. Below is a one-liner using <code>unlist()</code> which converts list objects into vectors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idata[id] =<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">unlist</span>(idata[id]))</code></pre></div>
<p><em>Another</em> one-liner to acheive the same result uses <strong>dplyr</strong>’s <code>mutate_each</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idata =<span class="st"> </span><span class="kw">mutate_each</span>(idata, <span class="kw">funs</span>(as.numeric), id)</code></pre></div>
<p>As with other operations there are other ways of achieving the same result in R, including the use of loops via <code>apply()</code> and <code>for()</code>. These are shown in the chapter’s <a href="https://github.com/csgillespie/efficientR">source code</a>.</p>
</div>
<div id="filtering-rows" class="section level3">
<h3><span class="header-section-number">4.5.3</span> Filtering rows</h3>
<p>The standard way to subset data by rows in R is with square brackets, for example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aus1 =<span class="st"> </span>idata[idata$Country ==<span class="st"> &quot;Australia&quot;</span>,]</code></pre></div>
<p><strong>dplyr</strong> offers an alternative and more flexible way of filtering data, using <code>filter()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aus2 =<span class="st"> </span><span class="kw">filter</span>(idata, Country ==<span class="st"> &quot;Australia&quot;</span>)</code></pre></div>
<p>In addition to being more flexible (see <code>?filter</code>), <code>filter</code> is slightly faster than base R’s notation.<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a> Note that <strong>dplyr</strong> does not use the <code>$</code> symbol: it knows that that <code>Country</code> is a variable of <code>idata</code>: the first argument of <strong>dplyr</strong> functions usually a <code>data.frame</code>, and subsequent in this context variable names can be treated as vector objects.<a href="#fn16" class="footnoteRef" id="fnref16"><sup>16</sup></a></p>
<p>There are <strong>dplyr</strong> equivalents of many base R functions but these usually work slightly differently. The <strong>dplyr</strong> equivalent of <code>aggregate</code>, for example is to use the grouping function <code>group_by</code> in combination with the general purpose function <code>summarise</code> (not to be confused with <code>summary</code> in base R), as we shall see in Section <a href="efficient-workflow.html#data-aggregation">4.5.5</a>. For consistency, however, we next look at filtering columns.</p>
</div>
<div id="filtering-columns" class="section level3">
<h3><span class="header-section-number">4.5.4</span> Filtering columns</h3>
<p>Large datasets often contain much worthless or blank information. This consumes RAM and reduces computational efficiency. Being able to focus quickly only on the variables of interest becomes especially important when handling large datasets.</p>
<p>Imagine that we have a text file called <code>miniaa</code> which is large enough to consume most of your computer’s RAM. We can load it with the following command:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fname =<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/miniaa&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;efficient&quot;</span>)
df =<span class="st"> </span><span class="kw">read.csv</span>(fname) <span class="co"># load imaginary large data</span>
<span class="kw">dim</span>(df)
<span class="co">#&gt; [1]   9 329</span></code></pre></div>
<p>Note that the data frame has 329 columns, and imagine it has millions of rows, instead of 9. That’s a lot of variables. Do we need them all? It’s worth taking a glimpse at this dataset to find out:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(df)</code></pre></div>
<pre><code># $ NPI                   (int) 1679576722, ...
# $ Entity Type Code      (int) 1, 1, 2,    ...
# $ Replacement NPI       (lgl) NA, NA, NA, ...
# ...</code></pre>
<p>Looking at the output, it becomes clear that the majority of the variables only contain <code>NA</code>. To clean the giant dataset, removing the empty columns, we need to identify which variables these are.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Identify the variable which are all NA</span>
all_na =<span class="st"> </span><span class="kw">sapply</span>(df, function(x) <span class="kw">all</span>(<span class="kw">is.na</span>(x)))
<span class="kw">summary</span>(all_na) <span class="co"># summary of the results</span>
<span class="co">#&gt;    Mode   FALSE    TRUE    NA&#39;s </span>
<span class="co">#&gt; logical      96     233       0</span>
df1 =<span class="st"> </span>df[!all_na] <span class="co"># subset the dataframe</span></code></pre></div>
<p>The new <code>df</code> object has fewer than a third of the original columns. Another way to save storage space, beyond removing the superfluous columns, is to save the dataset in R’s binary data format:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">saveRDS</span>(df1, <span class="st">&quot;data/miniaa.Rds&quot;</span>)</code></pre></div>
<div id="exercises-9" class="section level4">
<h4><span class="header-section-number">4.5.4.1</span> Exercises</h4>
<ol style="list-style-type: decimal">
<li><p>How much space was saved by reducing the number of columns? (Hint: use <code>object.size()</code>.)</p></li>
<li><p>How many times smaller is the .Rds file saved above compared with the .csv file? (Hint: use <code>file.size()</code>.)</p></li>
</ol>
</div>
</div>
<div id="data-aggregation" class="section level3">
<h3><span class="header-section-number">4.5.5</span> Data aggregation</h3>
<p>Data aggregation is the process of creating summaries of data based on a grouping variable. The end result usually has the same number of rows as there are groups. Because aggregation is a way of condensing datasets it can be a very useful technique for making sense of large datasets. The following code finds the number of unique countries (country being the grouping variable) from the ‘GHG’ dataset stored in the <strong>efficient</strong> package.</p>
<div class="rmdnote">
<p>
The GHG dataset used in the subsequent code reports the amount of greenhouse gas emissions emitted by country and by year for the major economic sectors. It was provided by the World Resources Institute and is available in raw form from their website: <a href="http://www.wri.org/resources/data-sets/cait-country-greenhouse-gas-emissions-data">wri.org/resources/data-sets/</a>.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fname =<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;extdata/ghg-ems.csv&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;efficient&quot;</span>)
df =<span class="st"> </span><span class="kw">read.csv</span>(fname)
<span class="kw">names</span>(df)
<span class="co">#&gt; [1] &quot;X&quot;                                       </span>
<span class="co">#&gt; [2] &quot;Country&quot;                                 </span>
<span class="co">#&gt; [3] &quot;Year&quot;                                    </span>
<span class="co">#&gt; [4] &quot;Electricity.Heat..CO2...MtCO2.&quot;          </span>
<span class="co">#&gt; [5] &quot;Manufacturing.Construction..CO2...MtCO2.&quot;</span>
<span class="co">#&gt; [6] &quot;Transportation..CO2...MtCO2.&quot;            </span>
<span class="co">#&gt; [7] &quot;Other.Fuel.Combustion..CO2...MtCO2.&quot;     </span>
<span class="co">#&gt; [8] &quot;Fugitive.Emissions..CO2...MtCO2.&quot;</span>
<span class="kw">nrow</span>(df)
<span class="co">#&gt; [1] 7896</span>
<span class="kw">length</span>(<span class="kw">unique</span>(df$Country))
<span class="co">#&gt; [1] 188</span></code></pre></div>
<p>Note that while there are almost 8000 rows, there are less than 200 countries. Referring back to Section <a href="efficient-workflow.html#renaming-columns">4.5.1</a>, the next stage should be to rename the columns so they are more convenient to work with. Having checked the verbose column names, this can be done in base R using the following command:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(df)[<span class="dv">4</span>:<span class="dv">8</span>] =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ECO2&quot;</span>, <span class="st">&quot;MCO2&quot;</span>, <span class="st">&quot;TCO2&quot;</span>, <span class="st">&quot;OCO2&quot;</span>, <span class="st">&quot;FCO2&quot;</span>)</code></pre></div>
<p>After the variable names have been updated, we can aggregate.<a href="#fn17" class="footnoteRef" id="fnref17"><sup>17</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">e_ems =<span class="st"> </span><span class="kw">aggregate</span>(df$ECO2, <span class="kw">list</span>(df$Country), mean, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>)
<span class="kw">nrow</span>(e_ems)
<span class="co">#&gt; [1] 188</span></code></pre></div>
<p>Note that the resulting data frame now has the same number of rows as there are countries: the aggregation has successfully reduced the number of rows we need to deal with. Now it is easier to find out per-country statistics, such as the three lowest emitters from electricity production:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(e_ems[<span class="kw">order</span>(e_ems$x),], <span class="dv">3</span>)
<span class="co">#&gt;     Group.1          x</span>
<span class="co">#&gt; 77  Iceland 0.01785714</span>
<span class="co">#&gt; 121   Nepal 0.02333333</span>
<span class="co">#&gt; 18    Benin 0.04642857</span></code></pre></div>
<p>Another way to specify the <code>by</code> argument is with the tilde (<code>~</code>). The following command creates the same object as <code>e_ems</code>, but with less typing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">e_ems =<span class="st"> </span><span class="kw">aggregate</span>(ECO2 ~<span class="st"> </span>Country, df, mean, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>)</code></pre></div>
<p>To aggregate the dataset using <strong>dplyr</strong> package one would divide the task in two: to <em>group</em> the dataset first and then to summarise, as illustrated below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;dplyr&quot;</span>)
<span class="kw">group_by</span>(df, Country) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean_eco2 =</span> <span class="kw">mean</span>(ECO2, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt; Source: local data frame [188 x 2]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;              Country   mean_eco2</span>
<span class="co">#&gt;               (fctr)       (dbl)</span>
<span class="co">#&gt; 1        Afghanistan         NaN</span>
<span class="co">#&gt; 2            Albania   0.6411905</span>
<span class="co">#&gt; 3            Algeria  23.0147619</span>
<span class="co">#&gt; 4             Angola   0.7914286</span>
<span class="co">#&gt; 5  Antigua &amp; Barbuda         NaN</span>
<span class="co">#&gt; 6          Argentina  39.1054762</span>
<span class="co">#&gt; 7            Armenia   1.8000000</span>
<span class="co">#&gt; 8          Australia 150.5961905</span>
<span class="co">#&gt; 9            Austria  17.3202381</span>
<span class="co">#&gt; 10        Azerbaijan  16.0430435</span>
<span class="co">#&gt; ..               ...         ...</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">countries =<span class="st"> </span><span class="kw">group_by</span>(idata, Country)
<span class="kw">summarise</span>(countries, <span class="dt">gini =</span> <span class="kw">mean</span>(gini, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>))
<span class="co">#&gt; Source: local data frame [176 x 2]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;         Country     gini</span>
<span class="co">#&gt;           (chr)    (dbl)</span>
<span class="co">#&gt; 1   Afghanistan      NaN</span>
<span class="co">#&gt; 2       Albania 30.43167</span>
<span class="co">#&gt; 3       Algeria 37.76000</span>
<span class="co">#&gt; 4        Angola 50.65000</span>
<span class="co">#&gt; 5     Argentina 48.06739</span>
<span class="co">#&gt; 6       Armenia 33.72929</span>
<span class="co">#&gt; 7     Australia 33.14167</span>
<span class="co">#&gt; 8       Austria 29.15167</span>
<span class="co">#&gt; 9    Azerbaijan 24.79000</span>
<span class="co">#&gt; 10 Bahamas, The      NaN</span>
<span class="co">#&gt; ..          ...      ...</span></code></pre></div>
<p>Note that <code>summarise</code> is highly versatile, and can be used to return a customised range of summary statistics:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summarise</span>(countries,
  <span class="co"># number of rows per country</span>
  <span class="dt">obs =</span> <span class="kw">n</span>(), 
  <span class="dt">med_t10 =</span> <span class="kw">median</span>(top10, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>),
  <span class="co"># standard deviation</span>
  <span class="dt">sdev =</span> <span class="kw">sd</span>(gini, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>), 
  <span class="co"># number with gini &gt; 30</span>
  <span class="dt">n30 =</span> <span class="kw">sum</span>(gini &gt;<span class="st"> </span><span class="dv">30</span>, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>), 
  <span class="dt">sdn30 =</span> <span class="kw">sd</span>(gini[ gini &gt;<span class="st"> </span><span class="dv">30</span> ], <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>),
  <span class="co"># range</span>
  <span class="dt">dif =</span> <span class="kw">max</span>(gini, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>) -<span class="st"> </span><span class="kw">min</span>(gini, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>)
  )
<span class="co">#&gt; Source: local data frame [176 x 7]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;         Country   obs med_t10      sdev   n30      sdn30   dif</span>
<span class="co">#&gt;           (chr) (int)   (dbl)     (dbl) (int)      (dbl) (dbl)</span>
<span class="co">#&gt; 1   Afghanistan    40      NA       NaN     0         NA    NA</span>
<span class="co">#&gt; 2       Albania    40  24.435  1.252524     3  0.3642801  2.78</span>
<span class="co">#&gt; 3       Algeria    40  29.780  3.436539     2  3.4365390  4.86</span>
<span class="co">#&gt; 4        Angola    40  38.555 11.299566     2 11.2995664 15.98</span>
<span class="co">#&gt; 5     Argentina    40  36.320  3.182462    23  3.1824622 11.00</span>
<span class="co">#&gt; 6       Armenia    40  27.835  4.019532    12  3.9567778 14.84</span>
<span class="co">#&gt; 7     Australia    40  24.785  1.075089     6  1.0750891  2.81</span>
<span class="co">#&gt; 8       Austria    40  23.120  3.120849     4  0.6859300  8.48</span>
<span class="co">#&gt; 9    Azerbaijan    40  17.960  9.479029     3  1.7386489 20.27</span>
<span class="co">#&gt; 10 Bahamas, The    40      NA       NaN     0         NA    NA</span>
<span class="co">#&gt; ..          ...   ...     ...       ...   ...        ...   ...</span></code></pre></div>
<p>To showcase the power of <code>summarise</code> used on a <code>grouped_df</code>, the above code reports a wide range of customised summary statistics <em>per country</em>:</p>
<ul>
<li>the number of rows in each country group</li>
<li>standard deviation of gini indices</li>
<li>median proportion of income earned by the top 10%</li>
<li>the number of years in which the gini index was greater than 30</li>
<li>the standard deviation of gini index values over 30</li>
<li>the range of gini index values reported for each country.</li>
</ul>
<div id="exercises-10" class="section level4">
<h4><span class="header-section-number">4.5.5.1</span> Exercises</h4>
<ol style="list-style-type: decimal">
<li><p>Referring back to Section <a href="efficient-workflow.html#renaming-columns">4.5.1</a>, rename the variables 4 to 8 using the <strong>dplyr</strong> function <code>rename</code>. Follow the pattern <code>ECO2</code>, <code>MCO2</code> etc.</p></li>
<li><p>Explore <strong>dplyr</strong>’s documentation, starting with the introductory vignette, accessed by entering <a href="https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html"><code>vignette(&quot;introduction&quot;)</code></a>.</p></li>
<li><p>Test additional <strong>dplyr</strong> ‘verbs’ on the <code>idata</code> dataset. (More vignette names can be discovered by typing <code>vignette(package = &quot;dplyr&quot;)</code>.)</p></li>
</ol>
</div>
</div>
<div id="chaining-operations" class="section level3">
<h3><span class="header-section-number">4.5.6</span> Chaining operations</h3>
<p>Another interesting feature of <strong>dplyr</strong> is its ability to chain operations together. This overcomes one of the aesthetic issues with R code: you can end end-up with very long commands with many functions nested inside each other to answer relatively simple questions.</p>
<blockquote>
<p>What were, on average, the 5 most unequal years for countries containing the letter g?</p>
</blockquote>
<p>Here’s how chains work to organise the analysis in a logical step-by-step manner:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">idata %&gt;%<span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">grepl</span>(<span class="st">&quot;g&quot;</span>, Country)) %&gt;%
<span class="st">  </span><span class="kw">group_by</span>(Year) %&gt;%
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">gini =</span> <span class="kw">mean</span>(gini, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>)) %&gt;%
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(gini)) %&gt;%
<span class="st">  </span><span class="kw">top_n</span>(<span class="dt">n =</span> <span class="dv">5</span>)
<span class="co">#&gt; Selecting by gini</span>
<span class="co">#&gt; Source: local data frame [5 x 2]</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;    Year   gini</span>
<span class="co">#&gt;   (int)  (dbl)</span>
<span class="co">#&gt; 1  1980 46.850</span>
<span class="co">#&gt; 2  1993 45.996</span>
<span class="co">#&gt; 3  2013 44.550</span>
<span class="co">#&gt; 4  1981 43.650</span>
<span class="co">#&gt; 5  2012 43.560</span></code></pre></div>
<p>The above function consists of 6 stages, each of which corresponds to a new line and <strong>dplyr</strong> function:</p>
<ol style="list-style-type: decimal">
<li>Filter-out the countries we’re interested in (any selection criteria could be used in place of <code>grepl(&quot;g&quot;, Country)</code>).</li>
<li>Group the output by year.</li>
<li>Summarise, for each year, the mean gini index.</li>
<li>Arrange the results by average gini index</li>
<li>Select only the top 5 most unequal years.</li>
</ol>
<p>To see why this method is preferable to the nested function approach, take a look at the latter. Even after indenting properly it looks terrible and is almost impossible to understand!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">top_n</span>(
  <span class="kw">arrange</span>(
    <span class="kw">summarise</span>(
      <span class="kw">group_by</span>(
        <span class="kw">filter</span>(idata, <span class="kw">grepl</span>(<span class="st">&quot;g&quot;</span>, Country)),
        Year),
      <span class="dt">gini =</span> <span class="kw">mean</span>(gini, <span class="dt">na.rm  =</span> <span class="ot">TRUE</span>)),
    <span class="kw">desc</span>(gini)),
  <span class="dt">n =</span> <span class="dv">5</span>)</code></pre></div>
<p>This section has provided only a taster of what is possible <strong>dplyr</strong> and why it makes sense from code writing and computational efficiency perspectives. For a more detailed account of data processing with R using this approach we recommend <em>R for Data Science</em> <span class="citation">(Grolemund and Wickham <a href="#ref-grolemund_r_2016">2016</a>)</span>.</p>
</div>
</div>
<div id="data-processing-with-data.table" class="section level2">
<h2><span class="header-section-number">4.6</span> Data processing with data.table</h2>
<p><strong>data.table</strong> is a mature package for fast data processing that presents an alternative to <strong>dplyr</strong>. There is some controversy about which is more appropriate for different tasks<a href="#fn18" class="footnoteRef" id="fnref18"><sup>18</sup></a> so it should be stated at the outset that <strong>dplyr</strong> and <strong>data.table</strong> are not mutually exclusive competitors. Both are excellent packages and the important thing from an efficiency perspective is that they can help speed up data processing tasks.</p>
<p>The foundational object class of <strong>data.table</strong> is the <code>data.table</code>. Like <strong>dplyr</strong>’s <code>tbl_df</code>, <strong>data.table</strong>’s <code>data.table</code> objects behave in the same was as the base <code>data.frame</code> class. However the <strong>data.table</strong> paradigm has some unique features that make it highly computationally efficient for many common tasks in data analysis. Building on subsetting methods using <code>[</code> and <code>filter()</code> presented in Section <a href="efficient-workflow.html#filtering-columns">4.5.4</a>, we’ll see <strong>data.tables</strong>’s unique approach to subsetting. Like base R <strong>data.table</strong> uses square brackets but you do not need to refer to the object name inside the brackets:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;data.table&quot;</span>)
idata =<span class="st"> </span><span class="kw">readRDS</span>(<span class="st">&quot;data/idata-renamed.Rds&quot;</span>)
idata_dt =<span class="st"> </span><span class="kw">data.table</span>(idata) <span class="co"># convert to data.table class</span>
aus3a =<span class="st"> </span>idata_dt[Country ==<span class="st"> &quot;Australia&quot;</span>]</code></pre></div>
<p>To boost performance, one can set ‘keys’. These are ‘<a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-keys-fast-subset.html">supercharged rownames</a>’ which order the table based on one or more variables. This allows a <em>binary search</em> algorithm to subset the rows of interest, which is much, much faster than the <em>vector scan</em> approach used in base R (see <a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-keys-fast-subset.html"><code>vignette(&quot;datatable-keys-fast-subset&quot;)</code></a>). <strong>data.table</strong> uses the key values for subsetting by default so the variable does not need to be mentioned again. Instead, using keys, the search criteria is provided as a list (invoked below with the concise <code>.()</code> syntax below).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">setkey</span>(idata_dt, Country)
aus3b =<span class="st"> </span>idata_dt[.(<span class="st">&quot;Australia&quot;</span>)]</code></pre></div>
<p>The result is the same, so why add the extra stage of setting the key? The reason is that this one-off sorting operation can lead to substantial performance gains in situations where repeatedly subsetting rows on large datasets consumes a large proportion of computational time in your workflow. This is illustrated in Figure <a href="efficient-workflow.html#fig:dtplot">4.4</a>, which compares 4 methods of subsetting incrementally larger versions of the <code>idata</code> dataset.</p>
<div class="figure"><span id="fig:dtplot"></span>
<img src="_main_files/figure-html/dtplot-1.png" alt="Benchmark illustrating the performance gains to be expected for different dataset sizes." width="576" />
<p class="caption">
Figure 4.4: Benchmark illustrating the performance gains to be expected for different dataset sizes.
</p>
</div>
<p>Figure <a href="efficient-workflow.html#fig:dtplot">4.4</a> demonstrates that <strong>data.table</strong> is <em>much faster</em> than base R and <strong>dplyr</strong> at subsetting. As with using external packages to read in data (see Section <a href="efficient-workflow.html#fread">4.3.1</a>), the relative benefits of <strong>data.table</strong> improve with dataset size, approaching a ~70 fold improvement on base R and a ~50 fold improvement on <strong>dplyr</strong> as the dataset size reaches half a Gigabyte. Interestingly, even the ‘non key’ implementation of <strong>data.table</strong> subset method is faster than the alternatives: this is because <strong>data.table</strong> creates a key internally by default before subsetting. The process of creating the key accounts for the ~10 fold speed-up in cases where the key has been pre-generated.</p>
<p>This section has introduced <strong>data.table</strong> as a complimentary approach to base and <strong>dplyr</strong> methods for data processing and illustrated the performance gains of using <em>keys</em> for subsetting tables. <strong>data.table</strong> is a mature and powerful package which uses clever computational principles implemented in C to provide efficient methods for a number of other operations for data analysis. These include highly efficient data reshaping, dataset merging (also known as joining, as with <code>left_join</code> in <strong>dplyr</strong>) and grouping. These are explained in the vignettes <a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.pdf"><code>datatable-intro</code></a> and <a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reshape.html"><code>datatable-reshape</code></a>. The <a href="https://cran.r-project.org/web/packages/data.table/vignettes/datatable-reference-semantics.html"><code>datatable-reference-semantics</code></a> vignette explains <strong>data.table</strong>’s unique syntax.</p>
</div>
<div id="publication" class="section level2">
<h2><span class="header-section-number">4.7</span> Publication</h2>
<!-- Thought: this should be more about 'getting your work out there' than packages-->
<p>The final stage in a typical project workflow is publication. This could be a report containing graphics produced by R, an online platform for exploring results or well-documented code that colleagues can use to improve their workflow. In every case the programming principles of reproducibility, modularity and DRY discussed in Chapter <a href="efficient-programming.html#efficient-programming">6</a> will make your publications faster to write, easier to maintain and more useful to others.</p>
<p>Instead of attempting a comprehensive treatment of the topic we will touch briefly on a couple of ways of documenting your work in R: dynamic reports and R packages. There is a wealth of material on each of these online. A wealth of online resources exists on each of these; to avoid duplication of effort the focus is on documentation from a workflow efficiency perspective.</p>
<div id="dynamic-documents-with-knitr" class="section level3">
<h3><span class="header-section-number">4.7.1</span> Dynamic documents with knitr</h3>
<p>When writing a report using R outputs a typical workflow has historically been to 1) do the analysis 2) save the resulting graphics and record the main results outside the R project and 3) open a program unrelated to R such as LibreOffice to import and communicate the results in prose. This is inefficient: it makes updating and maintaining the outputs difficult (when the data changes, steps 1 to 3 will have to be done again) and there is an overhead involved in jumping between incompatible computing environments.</p>
<p>To overcome this inefficiency in the documentation of R outputs the <strong>knitr</strong> package was developed. Used in conjunction with RStudio and building on a version of Markdown that accepts R code (RMarkdown, saved as .Rmd files) <strong>knitr</strong> allows for documents to be generated automatically. Results are generated <em>on the fly</em> by including ‘code chunks’ such as that illustrated below:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="dv">1</span>:<span class="dv">5</span>)^<span class="dv">2</span>
<span class="co">#&gt; [1]  1  4  9 16 25</span></code></pre></div>
<p>The resulting output is evaluated each time the document is compiled. To tell <strong>knitr</strong> that <code>(1:5)^2</code> is R code that needs to be evaluated, it must by preceded by <code>```{r}</code> on the line before the R code, and <code>```</code> at the end of the chunk. When you adapt to this workflow it is highly efficient, especially as RStudio provides a number of shortcuts that make it easy to create and modify code chunks. When the data or analysis code changes, the results will be updated in the document automatically. This can save hours of fiddly copying and pasting of R output between different programs.</p>
<p>Furthermore dynamic documents written in RMarkdown can compile into a range of output formats including html, pdf and Microsoft’s docx. There is a wealth of information on the details of dynamic report writing that is not worth replicating here. Key references are RStudio’s excellent website on RMarkdown hosted at <a href="http://rmarkdown.rstudio.com/">rmarkdown.rstudio.com/</a> and, for a more detailed account of dynamic documents with R, <span class="citation">(Xie <a href="#ref-xie2015dynamic">2015</a>)</span>.</p>
</div>
<div id="r-packages" class="section level3">
<h3><span class="header-section-number">4.7.2</span> R packages</h3>
<p>A strict approach to project management and workflow is treating your projects as R packages. This is good practice in terms of learning to correctly document your code, store example data, and even (via vignettes) ensure reproducibility. This approach to R workflow is appropriate for managing complex projects which repeatedly use the same routines which can be converted into functions. Creating project packages can provide foundation for generalising your code for use by others, e.g. via publication on GitHub or CRAN.</p>
<p>The number of essential elements of R packages differentiate them from other R projects. Three of these are outlined below from an efficiency perspective.</p>
<ul>
<li><p>The <a href="http://r-pkgs.had.co.nz/description.html"><code>DESCRIPTION</code></a> file contains key information about the package, including which packages are required for the code contained in your package to work, e.g. using <code>Imports:</code>. This is efficient because it means that anyone who installs your package will automatically install the other packages that it depends on.</p></li>
<li><p>The <code>R/</code> folder contains all the R code that defines your package’s functions. Placing your code in a single place and encouraging you to make your code modular in this way can greatly reduce duplication of code on large projects. Furthermore the documentation of R packages through <a href="http://r-pkgs.had.co.nz/man.html#man-workflow">Roxygen tags</a> such as <code>#' This function does this...</code> makes it easy for others to use your work.</p></li>
<li><p>The <code>data/</code> folder contains example code for demonstrating to others how the functions work and transporting datasets that will be frequently used in your workflow. Data can be added automatically to your package project using the <strong>devtools</strong> package, with <code>devtools::use_data()</code>. This can increase efficiency by providing a way of distributing small to medium sized datasets and making them available when the package is loaded with the function <code>data('data_set_name')</code>.</p></li>
</ul>
<p>As with dynamic documents, package development is a large topic. For small ‘one-off’ projects the time taken in learning how to set-up a package may not be worth the savings. However packages provide a rigourous way of storing code, data and documentation that can greatly boost productivity in the long-run. For more on R packages see <span class="citation">(Wickham <a href="#ref-Wickham_2015">2015</a>)</span>.</p>

</div>
</div>
</div>
<h3><span class="header-section-number">9</span> Efficient Learning</h3>
<div id="refs" class="references">
<div id="ref-Wickham_2014">
<p>Wickham, Hadley. 2014b. “Tidy Data.” <em>The Journal of Statistical Software</em> 14 (5).</p>
</div>
<div id="ref-berkun2005art">
<p>Berkun, Scott. 2005. <em>The Art of Project Management</em>. O’Reilly.</p>
</div>
<div id="ref-PMBoK_2000">
<p>PMBoK, A. 2000. “Guide to the Project Management Body of Knowledge.” <em>Project Management Institute, Pennsylvania USA</em>.</p>
</div>
<div id="ref-Wickham_2015">
<p>Wickham, Hadley. 2015. <em>R Packages</em>. O’Reilly Media, Inc.</p>
</div>
<div id="ref-Eddelbuettel_2011">
<p>Eddelbuettel, Dirk, Romain François, J. Allaire, John Chambers, Douglas Bates, and Kevin Ushey. 2011. “Rcpp: Seamless R and C++ Integration.” <em>Journal of Statistical Software</em> 40 (8): 1–18.</p>
</div>
<div id="ref-kersten2011researcher">
<p>Kersten, Martin L, Stratos Idreos, Stefan Manegold, Erietta Liarou, and others. 2011. “The Researcher’s Guide to the Data Deluge: Querying a Scientific Database in Just a Few Seconds.” <em>PVLDB Challenges and Visions</em> 3.</p>
</div>
<div id="ref-Codd1979">
<p>Codd, E. F. 1979. “Extending the database relational model to capture more meaning.” <em>ACM Transactions on Database Systems</em> 4 (4): 397–434. doi:<a href="https://doi.org/10.1145/320107.320109">10.1145/320107.320109</a>.</p>
</div>
<div id="ref-Spector_2008">
<p>Spector, Phil. 2008. <em>Data Manipulation with R</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-grolemund_r_2016">
<p>Grolemund, Garrett, and Hadley Wickham. 2016. <em>R for Data Science</em>. 1 edition. O’Reilly Media.</p>
</div>
<div id="ref-xie2015dynamic">
<p>Xie, Yihui. 2015. <em>Dynamic Documents with R and Knitr</em>. Vol. 29. CRC Press.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="8">
<li id="fn8"><p>The Oxford Dictionary’s definition of workflow is similar, with a more industrial feel: “The sequence of industrial, administrative, or other processes through which a piece of work passes from initiation to completion.”<a href="efficient-workflow.html#fnref8">↩</a></p></li>
<li id="fn9"><p>A number of dedicated project management systems are now available to assist with this task. These include (in rough ascending order of scale and complexity): the web browser add-on <a href="https://www.zenhub.io/">ZenHub</a>, “the first and only project management suite that works natively within GitHub”; the web-based and easy-to-use <a href="https://trello.com/">Trello</a>; and the fully featured enterprise scale open source project management system <a href="https://www.openproject.org/">OpenProject</a>.<a href="efficient-workflow.html#fnref9">↩</a></p></li>
<li id="fn10"><p>The importance of workflow has not gone unnoticed by the R community and there are a number of different suggestions to boost R productivity. <a href="http://robjhyndman.com/hyndsight/workflow-in-r/">Rob Hyndman</a>, for example, advocates the strategy of using four self-contained scripts to break up R work into manageable chunks: <code>load.R</code>, <code>clean.R</code>, <code>func.R</code> and <code>do.R</code>.<a href="efficient-workflow.html#fnref10">↩</a></p></li>
<li id="fn11"><p>A number of programs have been developed to assist project management and planning, however. These include <a href="http://sourceforge.net/projects/projectlibre/">ProjectLibre</a> and <a href="http://sourceforge.net/projects/projectlibre/">GanttProject</a>.<a href="efficient-workflow.html#fnref11">↩</a></p></li>
<li id="fn12"><p>For a more comprehensive discussion of Gantt charts in R, please refer to <a href="http://stackoverflow.com/questions/3550341/gantt-charts-with-r">stackoverflow.com/questions/3550341</a>.<a href="efficient-workflow.html#fnref12">↩</a></p></li>
<li id="fn13"><p>An excellent overview of the ‘hadleyverse’ and its benefits is available from <a href="https://barryrowlingson.github.io/hadleyverse">barryrowlingson.github.io/hadleyverse</a>.<a href="efficient-workflow.html#fnref13">↩</a></p></li>
<li id="fn14"><p>Since R 3.2.3 the base function <code>download.file()</code> can be used to download from secure (<code>https://</code>) connections on any operating system.<a href="efficient-workflow.html#fnref14">↩</a></p></li>
<li id="fn15"><p>Note that <code>filter</code> is also the name of a function used in the base <strong>stats</strong> library. Usually packages avoid using names already taken in base R but this is an exception.<a href="efficient-workflow.html#fnref15">↩</a></p></li>
<li id="fn16"><p>Note that this syntax is a defining feature of <strong>dplyr</strong> and many of its functions work in the same way. Later we’ll learn how this syntax can be used alongside the <code>%&gt;%</code> ‘pipe’ command to write clear data manipulation commands.<a href="efficient-workflow.html#fnref16">↩</a></p></li>
<li id="fn17"><p>Note the first argument in the function is the vector we’re aiming to aggregate and the second is the grouping variable (in this case Countries). A quirk of R is that the grouping variable must be supplied as a list. Next we’ll see a way of writing this that is neater.<a href="efficient-workflow.html#fnref17">↩</a></p></li>
<li id="fn18"><p>One <a href="http://stackoverflow.com/questions/21435339">question</a> on the stackoverflow website titled ‘data.table vs dplyr’ illustrates this controversey and delves into the philosophy underlying each approach.<a href="efficient-workflow.html#fnref18">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="efficient-hardware.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="efficient-collaboration.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/csgillespie/efficientR/edit/master/04-workflow.Rmd",
"text": "Edit"
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
